% CREATED BY DAVID FRISK, 2016
\chapter{Results}
\section{Experiment 1: Baseline Evaluation \& Blindfolding}
Fig.~\ref{fig:training_metrics} shows metrics for each batch during training. % SD 2021-05-01 15:45:21 +0200: Aha, so the model was trained with vision, just evaluated blindfolded. Cf. Das one could also train it in blindfolded way.
Fig.~\ref{fig:baseline_metrics} shows metrics averaged for each epoch during the baseline evaluation. Fig.~\ref{fig:blindfolded_metrics} shows metrics averaged for each epoch during blindfolded evaluation. It's clear in these graphs that the evaluation results are more stable when the model is given images. As can be seen in Figures~\ref{fig:baseline_loss} \& ~\ref{fig:blindfolded_loss}, the model begins to overfit to the training data around epoch 10. \newline % SD 2021-05-01 15:48:38 +0200: I assume validation is performed after training each epoch. The model shows that a blindfolded model is more confused even during training which we can accept since the model is not really optimised on a blindfolded scenario. It would be interesting to see what would happen if the model is optimised on black images. Hence, you analysis raises new questions which would be interisting to answer. However, for the original question it would just be enough to report the final mean rank on the test set.
Table~\ref{tab:best_baseline} shows the checkpoints with lowest loss, highest accuracy, and lowest mean rank during the evaluation of the baseline, with the metric that was "best" during that checkpoint in bold. Table~\ref{tab:best_blindfolded} shows the same for blindfolded evaluation. Comparing their best, the blindfolded model has 4.7\% worse loss than the baseline, 0.212 higher loss, and 0.149 higher mean rank. \newline % SD 2021-05-01 15:57:27 +0200: But of course the points at which this was achieved are different. Hence, the best model that we produce using images is not the best model to work in a blindfolded scenario.
One question here is whether the blank inputs to the model are actively confusing it--in training it is always given an image, so this black input is a completely new case. This could also explain the differences to a previous student's course project, in which they found equivalent performance to baseline when the agent was given a random image from the dataset. One challenge here is that scenes are used for multiple questions, % SD 2021-05-01 15:59:17 +0200: the model might be getting the correct answers by chance. If we measure accuracy then we could integrate agreement by chance using the Kappa co-efficient: http://cswww.essex.ac.uk/technical-reports/2005/csm-437.pdf
so this leaves open the possibility that the item being asked about is actually present in the room. Even using scenes not included in the dataset would be difficult to control, since if you ask the agent 'what color is the bookshelf?', you would then need to confirm that no bookshelves are present in the random image. \newline

% SD 2021-05-01 16:03:30 +0200: There are a lot of questions that are interesting (and open) in this section, we could do more experiments and also there are diferent ways at looking at results. The focus on epochs shows how confused is your model during training when evaluated by blindfolded images. It is also interesting that the model gets more confused in later epochs, perhpas important vision information is only learned then? But how confused would be the best model that would be selected in training if blindfolded? What happens if we train the model blindfolded? We could therefore expand the discussion here significantly.

\begin{figure}[ht!]
	\centering
	% \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/baseline_and_blindfolding/images/ckpt_23_781_image.jpg}
        \includegraphics[width=\textwidth]{./figure/results/baseline_and_blindfolding/images/ckpt_23_781_image.jpg}
	\caption{Example VQA Result} % SD 2021-05-01 16:11:24 +0200: You would have to explain in the previous section why we have the input like this. The 5 frames probably means the last five actions taken by the navigation module (and not frames per second in the video sense.)
	\label{fig:example_vqa_result}
\end{figure}
	

\begin{figure}[ht!]
	\centering
	% \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/baseline_and_blindfolding/blindfolded/ckpt_23_1250_image.jpg}
        \includegraphics[width=\textwidth]{./figure/results/baseline_and_blindfolding/blindfolded/ckpt_23_1250_image.jpg}
	\caption{Example Blindfolded Result}
	\label{fig:example_blindfolded_result}
\end{figure}

\begin{figure}[ht!]
     \centering
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         % \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/baseline_and_blindfolding/training/accuracy.png}
         \includegraphics[width=\textwidth]{./figure/results/baseline_and_blindfolding/training/accuracy.png}
         \caption{Training Accuracy}
         \label{fig:training_accuracy}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         % \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/baseline_and_blindfolding/training/loss.png}
         \includegraphics[width=\textwidth]{./figure/results/baseline_and_blindfolding/training/loss.png}
         \caption{Training Loss}
         \label{fig:training_loss}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         % \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/baseline_and_blindfolding/training/mean_rank.png}
         \includegraphics[width=\textwidth]{./figure/results/baseline_and_blindfolding/training/mean_rank.png}
         \caption{Training Mean Rank}
         \label{fig:training_mean_rank}
     \end{subfigure}
     \caption{Training Metrics}
     \label{fig:training_metrics}
\end{figure}

\begin{figure}[ht!]
     \centering
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         % \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/baseline_and_blindfolding/images/avg val accuracy.png}
         \includegraphics[width=\textwidth]{./figure/results/baseline_and_blindfolding/images/avg val accuracy.png}
         \caption{Baseline Validation Accuracy} % SD 2021-05-01 16:14:52 +0200: What is smoothed 0.6?
         \label{fig:baseline_accuracy}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         % \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/baseline_and_blindfolding/images/avg val loss.png}
         \includegraphics[width=\textwidth]{./figure/results/baseline_and_blindfolding/images/avg val loss.png}
         \caption{Baseline Validation Loss}
         \label{fig:baseline_loss}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         % \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/baseline_and_blindfolding/images/avg val mean rank.png}
         \includegraphics[width=\textwidth]{./figure/results/baseline_and_blindfolding/images/avg val mean rank.png}
         \caption{Baseline Validation Mean Rank}
         \label{fig:baseline_mean_rank}
     \end{subfigure}
     \caption{Baseline Validation Metrics}
     \label{fig:baseline_metrics}
\end{figure}


\begin{figure}[ht!]
     \centering
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         % \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/baseline_and_blindfolding/blindfolded/avg val accuracy.png}
         \includegraphics[width=\textwidth]{./figure/results/baseline_and_blindfolding/blindfolded/avg val accuracy.png}
         \caption{Blindfolded Validation Accuracy}
         \label{fig:blindfolded_accuracy}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         % \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/baseline_and_blindfolding/blindfolded/avg val loss.png}
         \includegraphics[width=\textwidth]{./figure/results/baseline_and_blindfolding/blindfolded/avg val loss.png}
         \caption{Blindfolded Validation Loss}
         \label{fig:blindfolded_loss}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         % \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/baseline_and_blindfolding/blindfolded/avg val mean rank.png}
         \includegraphics[width=\textwidth]{./figure/results/baseline_and_blindfolding/blindfolded/avg val mean rank.png}
         \caption{Blindfolded Validation Mean Rank}
         \label{fig:blindfolded_mean_rank}
     \end{subfigure}
     \caption{Blindfolded Validation Metrics}
     \label{fig:blindfolded_metrics}
\end{figure}

\begin{table}[ht!]
\centering
\caption{"Best" Epochs During Baseline Evaluation}
\begin{tabular}{l | l | l | l}
Checkpoint & Loss & Accuracy & Mean Rank \\
\hline
8 & \textbf{2.204141} & 0.381122 & 4.341837 \\
15 & 2.404433 & \textbf{0.403061} & 4.138265 \\
23 & 2.691763 & 0.370408 & \textbf{4.110714}
\end{tabular}
\label{tab:best_baseline}
\end{table}

\begin{table}[ht!]
\centering
\caption{"Best" Epochs During Blindfolded Evaluation}
\begin{tabular}{l | l | l | l}
Checkpoint & Loss & Accuracy & Mean Rank \\
\hline
5 & \textbf{2.416477} & 0.246429 & 5.493877 \\
27 & 2.546098 & \textbf{0.355612} & 4.551021 \\
39 & 4.788071 & 0.307653 & \textbf{4.260204}
\end{tabular}
\label{tab:best_blindfolded}
\end{table}


\section{Experiment 2: Basic Semantic Categories}
In this experiment, the model was provided with semantic category information, as described in \ref{sec:exp_2}.
With the categories, the highest accuracy was 1.4\% higher than the baseline's highest accuracy, and the highest mean rank was 0.46 higher than the baseline's highest. \newline

% SD 2021-05-01 16:16:09 +0200: Note that since you are using a different model now the loss here is not comprabale with the loss of the previous baseline model. We need to find a way to demonstrate the improvement (or no improvement): the final mean rank on the test set?

\begin{figure}[ht!]
     \centering
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         % \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/semantic_categories/eval/avg val accuracy.png}
         \includegraphics[width=\textwidth]{./figure/results/semantic_categories/eval/avg val accuracy.png}
         \caption{Validation Accuracy}
         \label{fig:category_accuracy}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         % \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/semantic_categories/eval/avg val loss.png}
         \includegraphics[width=\textwidth]{./figure/results/semantic_categories/eval/avg val loss.png}
         \caption{Validation Loss}
         \label{fig:category_loss}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         % \includegraphics[width=\textwidth]{/home/yasmeen/Desktop/thesisproj/thesis/figure/results/semantic_categories/eval/avg val mean rank.png}
         \includegraphics[width=\textwidth]{./figure/results/semantic_categories/eval/avg val mean rank.png}
         \caption{Validation Mean Rank}
         \label{fig:category_mean_rank}
     \end{subfigure}
     \caption{Validation Metrics for model given semantic categories}
     \label{fig:category_metrics}
\end{figure}

\begin{table}[ht!]
\centering
\caption{"Best" Epochs During Evaluation of Model with Semantic Categories}
\begin{tabular}{l | l | l | l}
Checkpoint & Loss & Accuracy & Mean Rank \\
\hline
6 & \textbf{2.108628} & 0.372959 & 3.971939 \\
22 & 2.444937 & \textbf{0.417347} & 3.761735 \\
29 & 2.824962 & 0.402551 & \textbf{3.650510} 
\end{tabular}
\label{tab:best_category}
\end{table}


