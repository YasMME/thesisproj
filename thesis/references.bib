@book{CrangleSuppes:1994,
	address = {Stanford, California},
	author = {Crangle, Colleen and Suppes, Patrick},
	publisher = {CSLI Publications},
	title = {Language and learning for robots},
	year = {1994}}

@techreport{Tellex:2020aa,
	author = {Tellex, Stefanie},
	institution = {Brown University},
	month = {March 3},
	title = {Towards Complex Language in Partially Observed Environments},
	type = {MIT CSAIL Embodied Intelligence Seminar},
	year = {2020}}

@phdthesis{Dobnik:2009dz,
	address = {Oxford, United Kingdom},
	author = {Dobnik, Simon},
	month = {September 4},
	school = {University of Oxford: Faculty of Linguistics, Philology and Phonetics and The Queen's College},
	title = {Teaching mobile robots to use spatial words},
	year = {2009}}

@article{Kruijff:2007,
	author = {Kruijff, Geert-Jan M. and Zender, Hendrik and Jensfelt, Patric and Christensen, Henrik I.},
	journal = {International Journal of Advanced Robotic Systems},
	number = {1},
	pages = {125--138},
	title = {Situated dialogue and spatial organization: what, where... and why?},
	volume = {4},
	year = {2007}}

@article{Winograd:1972,
	author = {Winograd, Terry},
	crossref = {Winograd:1976},
	journal = {Cognitive Psychology},
	number = {1},
	title = {Understanding Natural Language},
	volume = {3},
	year = {1972}}

@inproceedings{Janarthanam:2012aa,
	address = {Seoul, South Korea},
	author = {Janarthanam, Srinivasan and Lemon, Oliver and Liu, Xingkun and Bartie, Phil and Mackaness, William and Dalmas, Tiphaine and Goetze, Jana},
	booktitle = {Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
	month = jul,
	pages = {134--136},
	publisher = {Association for Computational Linguistics},
	title = {Integrating Location, Visibility, and Question-Answering in a Spoken Dialogue System for Pedestrian City Exploration},
	year = {2012}}

@article{Fellner:2017aa,
	author = {Fellner, Irene and Huang, Haosheng and Gartner, Georg},
	journal = {ISPRS International Journal of Geo-Information},
	number = {6},
	pages = {183},
	title = {``Turn Left after the WC, and Use the Lift to Go to the 2nd Floor'' -- Generation of Landmark-Based Route Instructions for Indoor Navigation},
	volume = {6},
	year = {2017}}

@article{Tenbrink:2010qf,
	author = {Thora Tenbrink and Robert J. Ross and Kavita E. Thomas and Nina Dethlefs and Elena Andonova},
	journal = {Journal of Visual Languages and Computing},
	number = {5},
	pages = {292--309},
	title = {Route instructions in map-based human-human and human-computer dialogue: A comparative analysis},
	volume = {21},
	year = {2010}}

@inproceedings{Wallgrun:2007zr,
	address = {Berlin, Heidelberg},
	author = {Wallgr\"{u}n, Jan Oliver and Frommberger, Lutz and Wolter, Diedrich and Dylla, Frank and Freksa, Christian},
	booktitle = {Proceedings of the 2006 international conference on Spatial Cognition V: reasoning, action, interaction},
	pages = {39--58},
	publisher = {Springer-Verlag},
	series = {SC'06},
	title = {Qualitative spatial representation and reasoning in the SparQ-toolbox},
	year = {2007}}

@inproceedings{De-Cubber:2013aa,
	author = {G. {De Cubber} and D. {Doroftei} and D. {Serrano} and K. {Chintamani} and R. {Sabino} and S. {Ourevitch}},
	booktitle = {2013 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)},
	pages = {1-4},
	title = {The {EU-ICARUS} project: Developing assistive robotic tools for search and rescue operations},
	year = {2013}}

@article{Kruijff-Korbayova:2015aa,
	author = {Kruijff-Korbayov{\'a}, Ivana and Colas, Francis and Gianni, Mario and Pirri, Fiora and de Greeff, Joachim and Hindriks, Koen and Neerincx, Mark and {\"O}gren, Petter and Svoboda, Tom{\'a}{\v s} and Worst, Rainer},
	journal = {KI - K{\"u}nstliche Intelligenz},
	number = {2},
	pages = {193--201},
	title = {TRADR Project: Long-Term Human-Robot Teaming for Robot Assisted Disaster Response},
	volume = {29},
	year = {2015}}

@inproceedings{habitat19iccv,
  title     =     {Habitat: {A} {P}latform for {E}mbodied {AI} {R}esearch},
  author    =     {{Manolis Savva*} and {Abhishek Kadian*} and {Oleksandr Maksymets*} and Yili Zhao and Erik Wijmans and Bhavana Jain and Julian Straub and Jia Liu and Vladlen Koltun and Jitendra Malik and Devi Parikh and Dhruv Batra},
  booktitle =     {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year      =     {2019}
}

@misc{robotslang,
      title={The {R}obot{S}lang Benchmark: Dialog-guided Robot Localization and Navigation}, 
      author={Shurjo Banerjee and Jesse Thomason and Jason J. Corso},
      year={2020},
      eprint={2010.12639},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@misc{thomason2019visionanddialog,
      title={Vision-and-Dialog Navigation}, 
      author={Jesse Thomason and Michael Murray and Maya Cakmak and Luke Zettlemoyer},
      year={2019},
      eprint={1907.04957},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{hermann2017grounded,
      title={Grounded Language Learning in a Simulated 3D World}, 
      author={Karl Moritz Hermann and Felix Hill and Simon Green and Fumin Wang and Ryan Faulkner and Hubert Soyer and David Szepesvari and Wojciech Marian Czarnecki and Max Jaderberg and Denis Teplyashin and Marcus Wainwright and Chris Apps and Demis Hassabis and Phil Blunsom},
      year={2017},
      eprint={1706.06551},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@INPROCEEDINGS{thomason2019grounded,
  author={J. {Thomason} and A. {Padmakumar} and J. {Sinapov} and N. {Walker} and Y. {Jiang} and H. {Yedidsion} and J. {Hart} and P. {Stone} and R. J. {Mooney}},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)}, 
  title={Improving Grounded Natural Language Understanding through Human-Robot Dialog}, 
  year={2019},
  volume={},
  number={},
  pages={6934-6941},
  doi={10.1109/ICRA.2019.8794287}}
  
  @article{Kadian_2020,
   title={Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World Performance?},
   volume={5},
   ISSN={2377-3774},
   url={http://dx.doi.org/10.1109/LRA.2020.3013848},
   DOI={10.1109/lra.2020.3013848},
   number={4},
   journal={IEEE Robotics and Automation Letters},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Kadian, Abhishek and Truong, Joanne and Gokaslan, Aaron and Clegg, Alexander and Wijmans, Erik and Lee, Stefan and Savva, Manolis and Chernova, Sonia and Batra, Dhruv},
   year={2020},
   month={Oct},
   pages={6670â€“6677}
}

@article{karpathy2014captioning,
author = {Socher, Richard and Karpathy, Andrej and Le, Quoc                             V. and Manning, Christopher D. and Ng, Andrew Y.},
title = {Grounded Compositional Semantics for Finding and Describing Images                     with Sentences},
journal = {Transactions of the Association for Computational Linguistics},
volume = {2},
number = {},
pages = {207-218},
year = {2014},
doi = {10.1162/tacl\_a\_00177},
URL = {https://doi.org/10.1162/tacl_a_00177},
eprint = {https://doi.org/10.1162/tacl_a_00177}
}

@article{lauria2002,
title = "Mobile robot programming using natural language",
journal = "Robotics and Autonomous Systems",
volume = "38",
number = "3",
pages = "171 - 181",
year = "2002",
note = "Advances in Robot Skill Learning",
issn = "0921-8890",
doi = "https://doi.org/10.1016/S0921-8890(02)00166-5",
url = "http://www.sciencedirect.com/science/article/pii/S0921889002001665",
author = "Stanislao Lauria and Guido Bugmann and Theocharis Kyriacou and Ewan Klein",
}

@inproceedings{embodiedqa, 
  title={Embodied Question Answering},
  author={Abhishek Das and Samyak Datta and Georgia Gkioxari and Stefan Lee and Devi Parikh and Dhruv Batra},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@inproceedings{eqa_multitarget,
  title={Multi-Target Embodied Question Answering},
  author={Licheng Yu and Xinlei Chen and Georgia Gkioxari and Mohit Bansal and Tamara L. Berg and Dhruv Batra},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@InProceedings{vqa_2015,
author = {Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C. Lawrence and Parikh, Devi},
title = {VQA: Visual Question Answering},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}


@InProceedings{suncg,
author = {Song, Shuran and Yu, Fisher and Zeng, Andy and Chang, Angel X. and Savva, Manolis and Funkhouser, Thomas},
title = {Semantic Scene Completion From a Single Depth Image},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@article{blindfolded,
  author    = {Ankesh Anand and
               Eugene Belilovsky and
               Kyle Kastner and
               Hugo Larochelle and
               Aaron C. Courville},
  title     = {Blindfold Baselines for Embodied {QA}},
  journal   = {CoRR},
  volume    = {abs/1811.05013},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.05013},
  archivePrefix = {arXiv},
  eprint    = {1811.05013}
}

@inproceedings{bleu,
  author={Kishore Papineni and Salim Roukos and Todd Ward and Wei-Jing Zhu},
  title={Bleu: a Method for Automatic Evaluation of Machine Translation},
  year={2002},
  cdate={1009843200000},
  pages={311-318},
  url={http://www.aclweb.org/anthology/P02-1040.pdf},
  booktitle={ACL}
}

@InProceedings{clevr,
author = {Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C. and Girshick, Ross},
title = {CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@article{matterport,
  author    = {Angel X. Chang and
               Angela Dai and
               Thomas A. Funkhouser and
               Maciej Halber and
               Matthias Nie{\ss}ner and
               Manolis Savva and
               Shuran Song and
               Andy Zeng and
               Yinda Zhang},
  title     = {Matterport3D: Learning from {RGB-D} Data in Indoor Environments},
  journal   = {CoRR},
  volume    = {abs/1709.06158},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.06158}
}

@misc{planner5d, 
author = {William H. Orrick}, 
title = {{UAB} "{P}lanner5{D}" v. {F}acebook, {I}nc.},
url = {https://casetext.com/case/uab-planner5d-v-facebook-inc/?PHONE_NUMBER_GROUP=C}, 
notes = {UAB "Planner5D" v. Facebook, Inc., Case No. 19-cv-03132-WHO (N.D. Cal. Jul. 24, 2020)}}

@inproceedings{eqa_matterport,
  title={{E}mbodied {Q}uestion {A}nswering in {P}hotorealistic {E}nvironments with {P}oint {C}loud {P}erception},
  author={Erik Wijmans and Samyak Datta and Oleksandr Maksymets and Abhishek Das and Georgia Gkioxari and Stefan Lee and Irfan Essa and Devi Parikh and Dhruv Batra},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@article{VLBERT,
  author    = {Weijie Su and
               Xizhou Zhu and
               Yue Cao and
               Bin Li and
               Lewei Lu and
               Furu Wei and
               Jifeng Dai},
  title     = {{VL-BERT:} Pre-training of Generic Visual-Linguistic Representations},
  journal   = {CoRR},
  volume    = {abs/1908.08530},
  year      = {2019},
  url       = {http://arxiv.org/abs/1908.08530},
  eprint    = {1908.08530}
}

@inproceedings{densecap,
  title={DenseCap: Fully Convolutional Localization Networks for Dense Captioning},
  author={Johnson, Justin and Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and 
             Pattern Recognition},
  year={2016}
}

@inproceedings{colorknowledge,
    title = "{K}nowledge Supports Visual Language Grounding: {A} Case Study on Colour Terms",
    author = {Sch{\"u}z, Simeon  and
      Zarrie{\ss}, Sina},
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.584",
    doi = "10.18653/v1/2020.acl-main.584",
    pages = "6536--6542",
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@article{kellycolors,
	title={Twenty-two colors of maximum contrast},
	author={Kenneth L. Kelly},
	journal={Color Engineering},
	volume={3},
	pages={26-27},
	year={1965},
	url={http://www.iscc-archive.org/pdf/PC54_1724_001.pdf}
}

@article{colorsincontext,
    author = {Monroe, Will and Hawkins, Robert
            X.D. and Goodman, Noah
            D. and Potts, Christopher},
    title = "{Colors in Context: A Pragmatic Neural Model for Grounded Language
                    Understanding}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {5},
    pages = {325-338},
    year = {2017},
    month = {09},
    abstract = "{We present a model of pragmatic referring expression interpretation in a grounded
                    communication task (identifying colors from descriptions) that draws upon
                    predictions from two recurrent neural network classifiers, a speaker and a
                    listener, unified by a recursive pragmatic reasoning framework. Experiments show
                    that this combined pragmatic model interprets color descriptions more accurately
                    than the classifiers from which it is built, and that much of this improvement
                    results from combining the speaker and listener perspectives. We observe that
                    pragmatic reasoning helps primarily in the hardest cases: when the model must
                    distinguish very similar colors, or when few utterances adequately express the
                    target color. Our findings make use of a newly-collected corpus of human
                    utterances in color reference games, which exhibit a variety of pragmatic
                    behaviors. We also show that the embedded speaker model reproduces many of these
                    pragmatic behaviors.}",
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00064},
    url = {https://doi.org/10.1162/tacl\_a\_00064},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00064/1567474/tacl\_a\_00064.pdf},
}

@article{vqa_survey,
title = {Visual question answering: A survey of methods and datasets},
journal = {Computer Vision and Image Understanding},
volume = {163},
pages = {21-40},
year = {2017},
note = {Language in Vision},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2017.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1077314217300772},
author = {Qi Wu and Damien Teney and Peng Wang and Chunhua Shen and Anthony Dick and Anton {van den Hengel}},
keywords = {Visual question answering, Natural language processing, Knowledge bases, Recurrent neural networks},
abstract = {Visual Question Answering (VQA) is a challenging task that has received increasing attention from both the computer vision and the natural language processing communities. Given an image and a question in natural language, it requires reasoning over visual elements of the image and general knowledge to infer the correct answer. In the first part of this survey, we examine the state of the art by comparing modern approaches to the problem. We classify methods by their mechanism to connect the visual and textual modalities. In particular, we examine the common approach of combining convolutional and recurrent neural networks to map images and questions to a common feature space. We also discuss memory-augmented and modular architectures that interface with structured knowledge bases. In the second part of this survey, we review the datasets available for training and evaluating VQA systems. The various datatsets contain questions at different levels of complexity, which require different capabilities and types of reasoning. We examine in depth the question/answer pairs from the Visual Genome project, and evaluate the relevance of the structured annotations of images with scene graphs for VQA. Finally, we discuss promising future directions for the field, in particular the connection to structured knowledge bases and the use of natural language processing models.}
}

@InProceedings{das2017,
author = {Das, Abhishek and Kottur, Satwik and Gupta, Khushi and Singh, Avi and Yadav, Deshraj and Moura, Jose M. F. and Parikh, Devi and Batra, Dhruv},
title = {Visual Dialog},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@article{meetup,
  author    = {Nikolai Ilinykh and
               Sina Zarrie{\ss} and
               David Schlangen},
  title     = {MeetUp! {A} Corpus of Joint Activity Dialogues in a Visual Environment},
  journal   = {CoRR},
  volume    = {abs/1907.05084},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.05084},
  archivePrefix = {arXiv},
  eprint    = {1907.05084},
  timestamp = {Wed, 17 Jul 2019 10:27:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-05084.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{whereareyou,
      title={Where Are You? Localization from Embodied Dialog}, 
      author={Meera Hahn and Jacob Krantz and Dhruv Batra and Devi Parikh and James M. Rehg and Stefan Lee and Peter Anderson},
      year={2020},
      eprint={2011.08277},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{10.1145/325334.325242,
author = {Shoemake, Ken},
title = {Animating Rotation with Quaternion Curves},
year = {1985},
isbn = {0897911660},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/325334.325242},
doi = {10.1145/325334.325242},
abstract = {Solid bodies roll and tumble through space. In computer animation, so do cameras. The rotations of these objects are best described using a four coordinate system, quaternions, as is shown in this paper. Of all quaternions, those on the unit sphere are most suitable for animation, but the question of how to construct curves on spheres has not been much explored. This paper gives one answer by presenting a new kind of spline curve, created on a sphere, suitable for smoothly in-betweening (i.e. interpolating) sequences of arbitrary rotations. Both theory and experiment show that the motion generated is smooth and natural, without quirks found in earlier methods.},
booktitle = {Proceedings of the 12th Annual Conference on Computer Graphics and Interactive Techniques},
pages = {245â€“254},
numpages = {10},
keywords = {in-betweening, B-spline, rotation, spline, approximation, B\'{e}zier curve, quaternion, spherical geometry, animation, interpolation},
series = {SIGGRAPH '85}
}

@article{quaternions,
author = {Shoemake, Ken},
title = {Animating Rotation with Quaternion Curves},
year = {1985},
issue_date = {Jul. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {0097-8930},
url = {https://doi.org/10.1145/325165.325242},
doi = {10.1145/325165.325242},
journal = {SIGGRAPH Comput. Graph.},
month = jul,
pages = {245â€“254},
}


@misc{replica,
      title={The Replica Dataset: A Digital Replica of Indoor Spaces}, 
      author={Julian Straub and Thomas Whelan and Lingni Ma and Yufan Chen and Erik Wijmans and Simon Green and Jakob J. Engel and Raul Mur-Artal and Carl Ren and Shobhit Verma and Anton Clarkson and Mingfei Yan and Brian Budge and Yajie Yan and Xiaqing Pan and June Yon and Yuyang Zou and Kimberly Leon and Nigel Carter and Jesus Briales and Tyler Gillingham and Elias Mueggler and Luis Pesqueira and Manolis Savva and Dhruv Batra and Hauke M. Strasdat and Renzo De Nardi and Michael Goesele and Steven Lovegrove and Richard Newcombe},
      year={2019},
      eprint={1906.05797},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{visualnavigationsurvey,
title= {Visual Navigation for Mobile Robots: A Survey},
author={Francisco Bonin-Font, Alberto Ortiz, Gabriel Oliver},
journal={Journal of Intelligent and Robotic Systems},
year={2008},
volume={53},
number={3}
}

@misc{objectnavrevisited,
      title={ObjectNav Revisited: On Evaluation of Embodied Agents Navigating to Objects}, 
      author={Dhruv Batra and Aaron Gokaslan and Aniruddha Kembhavi and Oleksandr Maksymets and Roozbeh Mottaghi and Manolis Savva and Alexander Toshev and Erik Wijmans},
      year={2020},
      eprint={2006.13171},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
