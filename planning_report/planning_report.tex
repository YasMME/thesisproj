\documentclass{article}

\usepackage[utf8]{inputenc}

%\usepackage{natbib}
\usepackage{hyperref}

\usepackage{graphicx}

\usepackage[colorinlistoftodos]{todonotes}

\usepackage{parskip}
\setlength{\parskip}{10pt} 

\usepackage{tikz}
\usetikzlibrary{arrows, decorations.markings}

\usepackage{outlines}

\usepackage{chngcntr}
\counterwithout{figure}{section}

\usepackage{pgfgantt}



\begin{document}


\begin{titlepage}
  

\centering
  
  
{\scshape\LARGE Master thesis Planning Report\\}
  
\vspace{0.5cm}
  
{\huge\bfseries Injection of Information to Embodied Agents\\}

  
\vspace{2cm}
  
{\Large Yasmeen Emampoor (gusemampya@student.gu.se)\\}
  
\vspace{1.0cm}
  
{\large Supervisor: Simon Dobnik (FLoV)\\}
  
\vspace{1.5cm}

\end{titlepage}
  
\section{Introduction}
\subsection{Background}
\todo{Why is it relevant?}

Robots have the potential to be useful in many fieldsâ€“they can perform tasks
that are dangerous for humans, as well as tasks that are simply tedious. These
robots are often operated based on pre-defined actions, or remotely. The potential increases in efficiency from being able to give a goal/task in natural language and have the robot interpret and determine how to carry out this task are huge. \\
For a household agent, it would be great to be able to interact with a robot in a similar way to how one would with another person. 
\begin{verbatim}
Human: Go get my computer from the office. 
Robot navigates to the office, finds the computer, brings it back. 
Human: Were my keys in the office?
Robot: I don't know, I'll go check. 
Robot navigates to the office, finds the keys. Returns.
Robot: Yes, they are on the bookshelf. 
Human: Thanks. 
\end{verbatim}
For this project, I'll be considering a simpler dialogue stub: the human asks a question, and the robot answers. 
\begin{verbatim}
Q: Where is the computer?
A: In the office. 
\end{verbatim}
\todo{rephrase so not exactly the same as proposal}

\subsection{Aim}
\todo{The aim is a brief description of the task and its intended outcome.}The task in which an embodied agent is asked a question and must move within its surroundings in order to answer it is called Embodied Question Answering (EQA). \\
The aim of this thesis is to identify ways in which prior or extra knowledge can be used to improve model performance in an EQA task. 

\subsection{Formulation}
\todo{The formulation of the problem at hand and the assignment. This should include an extended version of the scientific problem definition and references to knowledge within the area given in the thesis proposal.}
\todo{dataset first mention here? Photo-realistic paper}

Hypotheses: 
\begin{outline}
	\1 The VQA model does consider the visual features when answering the questions.
		\2 If true, additional view points can improve performance in the VQA task. 
	\1 Additional semantic information can be used to improve performance in the VQA task. 
	\1 Additional semantic information can be used to improve performance in Navigation task. 
\end{outline}



\subsection{Limitations}
\todo{This chapter describes what issues will not be dealt with in the work.}
The main dataset of questions and answers available for EQA was automatically generated, and may contain some errors. One example of this is shown in Fig.~\ref{fig:err_ex}, in which a VQA model answered that the sofa in the living room is tan, but the ground truth answer is that it is yellow. However, looking at the image, I see a tan sofa and a yellow armchair. It seems that an error was likely made in the automatic question/answer generation, identifying the armchair as a sofa, but the model is not making the same error. \\
\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{../error_images/ckpt_0_121_image.jpg}
	\caption{Error Example}
	\label{fig:err_ex}
\end{figure}
Certain colors, such as brown, are also over represented in the dataset. However, I plan to work with this dataset as is, rather than attempting to balance presence of colors, or manually remove incorrect question answer pairs. This is both due to time limitations, and due to not wanting to introduce artificial balance--many things in houses are made of wood, and are therefore brown. It's not necessarily a bad thing for the system to expect tables to be brown, as long as it is also actually looking for a table to answer the question. \\
A dataset was collected using humans via Amazon Mechanical Turk, but it relies on a house dataset that is no longer available. \\
\todo{classification vs generation}
 

\section{Methodology}
\todo{The methodology chapter describes how the work is structured. It includes workflows, design of experiments and use of various data collection methods.}
\todo{mltgpu, metrics under consideration, blindfolded check after every change, enable the semantic sensor during VQA (talk about semantic annotations from matterport), implement look-around, enable the semantic sensor during navigation, discussion of other semantic options}

I am starting with the Embodied Question Answering baseline in Habitat-Lab, which consists of three parts, a CNN for initial feature extraction, a question answering module, and a navigation module, called Pacman\cite{embodiedqa}. I am using the EQA task dataset, which was created using code to automatically generate questions and answers to correspond with scenes in the Matterport3D dataset\cite{matterport}. \\

\section{Schedule}
\begin{ganttchart}[
	hgrid=true,
	vgrid=true,
	bar/.append style={fill=gray},
	canvas/.append style={fill=none},
	link/.append style={thick}
	]{1}{17}
	\gantttitle{Schedule}{17} \\
	\gantttitlelist{5, ..., 21}{1} \\
	\ganttbar{Getting GPU Access}{2}{2} \\
	\ganttbar{Attend presentation on blindfolding}{2}{2} \\
	\ganttbar{Learning Habitat}{1}{6} \\
	\ganttbar{Writing Seminar I}{2}{2} \\
	\ganttbar{Train\&Eval.Baseline, blindfolded\&normal}{6}{7} \\
	\ganttbar{Enable Semantic Sensor during VQA}{8}{10} \\
	\ganttbar{Implement Look Around}{8}{10} \\
	\ganttbar{Enable Semantic Sensor during Nav}{11}{13} \\
	\ganttbar[bar/.append style={fill=red}]{GPU Off}{8}{8} \\
	\ganttbar[bar/.append style={fill=cyan}]{Writing Seminar II}{12}{14} \\
	\ganttbar{Writing!}{14}{16} \\
	\begin{scope}[on background layer]
	\ganttlink{elem0}{elem4}
	\ganttlink{elem4}{elem5}
	\ganttlink{elem4}{elem6}
	\ganttlink{elem4}{elem7}
	\end{scope}
\end{ganttchart}
\todo{halftime report date}


\section{Risk Analysis and Ethical Considerations}
The main risks to completion of this project are related to running out of time--habitat is a new environment for me to work in, so unexpected difficulties are likely to pop up, and the data is too large to work locally, but there are always risks to working on shared servers--at the moment some of the GPUs in the cluster I am using are behaving strangely, and although the issue is under investigation, it is slowing down some of the work. \\
An important note ethically is that the original development of this model, not the version included in Habitat-Lab, but the original version associated with the EmbodiedQA project, was developed using a dataset that as of July 2020 was the subject of a lawsuit by the company Planner5D against Facebook and Princeton, on the grounds that the data was accessed without permission\cite{planner5d}.


\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}

