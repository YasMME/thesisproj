{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#Validation Set\n",
    "with open('val.json') as json_file:\n",
    "    val = json.load(json_file)\n",
    "episodes = val['episodes']\n",
    "type(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vocab_val = val['question_vocab']\n",
    "answer_vocab_val = val['answer_vocab']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_answer_vocab = set(a for a in answer_vocab_val['word_list'])\n",
    "len(unique_answer_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Unknowns\n",
    "qs = [item['question'] for item in episodes]\n",
    "qt = [item['question_text'] for item in qs]\n",
    "\n",
    "for q in qt:\n",
    "    if '<unk>' in q:\n",
    "        print(q)\n",
    "        \n",
    "ans = [item['answer_text'] for item in qs]\n",
    "for a in ans:\n",
    "    if '<unk>' in a:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bedroom',\n",
       " 'black',\n",
       " 'blue',\n",
       " 'brown',\n",
       " 'closet',\n",
       " 'family room',\n",
       " 'green',\n",
       " 'grey',\n",
       " 'gym',\n",
       " 'hallway',\n",
       " 'kitchen',\n",
       " 'laundry room',\n",
       " 'living room',\n",
       " 'lounge',\n",
       " 'off-white',\n",
       " 'olive green',\n",
       " 'red',\n",
       " 'red brown',\n",
       " 'silver',\n",
       " 'slate grey',\n",
       " 'spa',\n",
       " 'tan',\n",
       " 'white',\n",
       " 'yellow'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique Answers\n",
    "unique_as = set(a for a in ans)\n",
    "unique_as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Set\n",
    "with open('train.json') as json_file:\n",
    "    train = json.load(json_file)\n",
    "train_episodes = train['episodes']\n",
    "type(train_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_vocab_train = train['answer_vocab']\n",
    "question_vocab_train = train['question_vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Unknowns\n",
    "tqs = [item['question'] for item in train_episodes]\n",
    "tqt = [item['question_text'] for item in tqs]\n",
    "\n",
    "\n",
    "for tq in tqt:\n",
    "    if '<unk>' in tq:\n",
    "        print(tq)\n",
    "        \n",
    "tans = [item['answer_text'] for item in tqs]\n",
    "for ta in tans:\n",
    "    if '<unk>' in ta:\n",
    "        print(ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_tqs = [tq.replace(\"?\",\"\").split() for tq in tqt]\n",
    "training_question_vocab = set([item for sublist in split_tqs for item in sublist])\n",
    "#training_question_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_qs = [q.replace(\"?\",\"\").split() for q in qt]\n",
    "val_question_vocab = set([item for sublist in split_qs for item in sublist])\n",
    "#val_question_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toaster'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#objects only occuring in validation\n",
    "val_only_vocab = val_question_vocab - training_question_vocab\n",
    "val_only_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathroom',\n",
       " 'bedroom',\n",
       " 'black',\n",
       " 'blue',\n",
       " 'brown',\n",
       " 'closet',\n",
       " 'dining room',\n",
       " 'family room',\n",
       " 'foyer',\n",
       " 'green',\n",
       " 'grey',\n",
       " 'hallway',\n",
       " 'kitchen',\n",
       " 'laundry room',\n",
       " 'light blue',\n",
       " 'living room',\n",
       " 'lounge',\n",
       " 'off-white',\n",
       " 'office',\n",
       " 'olive green',\n",
       " 'orange yellow',\n",
       " 'purple',\n",
       " 'purple pink',\n",
       " 'red',\n",
       " 'red brown',\n",
       " 'silver',\n",
       " 'slate grey',\n",
       " 'spa',\n",
       " 'tan',\n",
       " 'tv room',\n",
       " 'white',\n",
       " 'yellow',\n",
       " 'yellow green',\n",
       " 'yellow pink'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique Answers\n",
    "unique_tas = set(ta for ta in tans)\n",
    "unique_tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_room_answers = []\n",
    "color_answers = []\n",
    "location_answers = []\n",
    "\n",
    "for item in tqs:\n",
    "    if item['question_type'] == 'color_room':\n",
    "        color_room_answers.append(item['answer_text'])\n",
    "    elif item['question_type'] == 'color':\n",
    "        color_answers.append(item['answer_text'])\n",
    "    elif item['question_type'] == 'location':\n",
    "        location_answers.append(item['answer_text'])\n",
    "    else:\n",
    "        print('uh oh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color_room 20\n",
      "color 11\n",
      "location 14\n"
     ]
    }
   ],
   "source": [
    "print('color_room', len(set(color_room_answers)))\n",
    "print('color', len(set(color_answers)))\n",
    "print('location', len(set(location_answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gym'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_only = set(unique_as - unique_tas)\n",
    "val_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('color_room', 69.85908141962422),\n",
       " ('color', 15.91858037578288),\n",
       " ('location', 14.222338204592901)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Percentages of Question Types\n",
    "tqtype = [item['question_type'] for item in tqs]\n",
    "q_num = len(tqtype)\n",
    "c = Counter(tqtype)\n",
    "type_percentages = [(i, c[i] / q_num * 100.0) for i in c]\n",
    "type_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('color_room', 68.46153846153847),\n",
       " ('color', 17.692307692307693),\n",
       " ('location', 13.846153846153847)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqtype = [item['question_type'] for item in qs]\n",
    "q_num = len(vqtype)\n",
    "c = Counter(vqtype)\n",
    "type_percentages = [(i, c[i] / q_num * 100.0) for i in c]\n",
    "type_percentages\n",
    "#c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11496\n",
      "Original dataset shape Counter({'color_room': 8031, 'color': 1830, 'location': 1635})\n",
      "Resampled dataset shape Counter({'color_room': 8031, 'color': 8031, 'location': 8031})\n"
     ]
    }
   ],
   "source": [
    "# Boosting the training set\n",
    "train_episodes = train['episodes']\n",
    "print(len(train_episodes))\n",
    "y = [item['question']['question_type'] for item in train_episodes]\n",
    "X = pd.DataFrame.from_dict(train_episodes)\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = pd.Series(range(0,len(X_res)))\n",
    "X_res['episode_id'] = eps\n",
    "X_res = X_res.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-374b3cf53795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'episodes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'question_vocab'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion_vocab_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'answer_vocab'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0manswer_vocab_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'boost_train.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/habitatenv/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_data = {'episodes': X_res, 'question_vocab': question_vocab_train, 'answer_vocab': answer_vocab_train}\n",
    "with open('boost_train.json', 'w') as f:\n",
    "    json.dump(new_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a mini-version of the dataset for local testing\n",
    "episodes[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matterport scenes to use in mini-dataset\n",
    "scenes = ['mp3d/1LXtFkjw3qL/1LXtFkjw3qL.glb', 'mp3d/1pXnuDYAj8r/1pXnuDYAj8r.glb', 'mp3d/2azQ1b91cZZ/2azQ1b91cZZ.glb', 'mp3d/2n8kARJN3HM/2n8kARJN3HM.glb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_val_episodes = list(filter(lambda d: d['scene_id'] in scenes, episodes))[:3]\n",
    "len(mini_val_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_val = {'episodes': mini_val_episodes, 'question_vocab': question_vocab_val, 'answer_vocab': answer_vocab_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_train_episodes = list(filter(lambda d: d['scene_id'] in scenes, train_episodes))[:3]\n",
    "mini_train = {'episodes': mini_train_episodes, 'question_vocab': question_vocab_train, 'answer_vocab': answer_vocab_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mini_train_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to json files\n",
    "\n",
    "with open('mini_train.json', 'w') as f:\n",
    "    json.dump(mini_train, f)\n",
    "    \n",
    "with open('mini_val.json', 'w') as f:\n",
    "    json.dump(mini_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(episodes[10]['shortest_paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitatenv",
   "language": "python",
   "name": "habitatenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
